{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3995, 520) (3995, 2) (106574, 519)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Nom des 519 features\n",
    "''' \n",
    "features = pd.read_csv(filepath_or_buffer=\"features_head.csv\", sep=\",\")\n",
    "#print(features.columns)\n",
    "\n",
    "\n",
    "'''\n",
    "Croisement features/tracks du dataset train\n",
    "''' \n",
    "traingenre = pd.read_csv(filepath_or_buffer=\"train_clean.csv\", sep=\",\")\n",
    "iter_csv = pd.read_csv(filepath_or_buffer=\"features_adapte.csv\", sep=\",\", iterator=True, chunksize=10000)\n",
    "datatrain = pd.concat([chunk for chunk in iter_csv])\n",
    "data = pd.merge(traingenre, datatrain, on='track_id')\n",
    "\n",
    "print(data.shape, traingenre.shape, datatrain.shape)\n",
    "#print(X_train.shape)\n",
    "#print(X_train.shape[1])\n",
    "#print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3995, 519)\n",
      "(3995,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Preparing Data\n",
    "'''\n",
    "\n",
    "X = data.drop('genre_id',axis=1)\n",
    "y = data['genre_id'].values\n",
    "\n",
    "#for i in range(len(y)):\n",
    "#    y[i] -= 1\n",
    "#y=to_categorical(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=100, learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Multi-layer Perceptron Classifier\n",
    "'''\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', \n",
    "                    alpha=0.001, \n",
    "                    hidden_layer_sizes=(100), \n",
    "                    random_state=1)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.41      0.41       179\n",
      "           2       0.22      0.38      0.28       161\n",
      "           3       0.34      0.27      0.30       170\n",
      "           4       0.11      0.05      0.07       166\n",
      "           5       0.14      0.15      0.15       165\n",
      "           6       0.11      0.11      0.11       169\n",
      "           7       0.17      0.20      0.18       157\n",
      "           8       0.10      0.07      0.08       152\n",
      "\n",
      "    accuracy                           0.21      1319\n",
      "   macro avg       0.20      0.20      0.20      1319\n",
      "weighted avg       0.20      0.21      0.20      1319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the Multi-layer Perceptron Classifier\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "#print(predictions)\n",
    "#print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA...\n",
      "Training KNN...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Nearest Neighbors Classifier\n",
    "'''\n",
    "print(\"PCA...\")\n",
    "pca = PCA(n_components=40).fit(X_train)\n",
    "X_reduce = pca.transform(X_train)\n",
    "\n",
    "print(\"Training KNN...\")\n",
    "model = KNeighborsClassifier(n_jobs=-1,n_neighbors=5,weights='uniform')\n",
    "model.fit(X_reduce, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2676, 519)\n",
      "(2676,)\n",
      "(1319, 519)\n",
      "(1319,)\n",
      "Training accuracy: 62.07%\n",
      "Test accuracy: 46.10%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the Nearest Neighbors Classifier\n",
    "\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "train_acc = model.score(X_reduce, y_train)\n",
    "test_acc = model.score(pca.transform(X_test), y_test)\n",
    "\n",
    "#print(predictions)\n",
    "#print(y_test)\n",
    "#print(confusion_matrix(y_test,predictions))\n",
    "#print(classification_report(y_test,predictions))\n",
    "\n",
    "print(f'Training accuracy: {train_acc * 100:.2f}%')\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Linear Regression Classifier\n",
    "'''\n",
    "\n",
    "model = SGDClassifier(loss=\"log\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 17.15%\n",
      "Test accuracy: 15.85%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the Linear Regression Classifier\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Training accuracy: {train_acc * 100:.2f}%')\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invite/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/invite/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/invite/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Logistic Regression Classifier\n",
    "'''\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 67.00%\n",
      "Test accuracy: 57.16%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the Logistic Regression Classifier\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Training accuracy: {train_acc * 100:.2f}%')\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Decision Tree Classifier\n",
    "'''\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 10, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 82.44%\n",
      "Test accuracy: 38.82%\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on training and test sets\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Training accuracy: {train_acc * 100:.2f}%')\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=None, n_estimators=700,\n",
       "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "XGBoost Classifier\n",
    "'''\n",
    "\n",
    "model = XGBClassifier(n_estimators=700,learning_rate=0.2, max_depth=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Test accuracy: 62.77%\n"
     ]
    }
   ],
   "source": [
    "## Evaluation of the XGBoost Classifier\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Training accuracy: {train_acc * 100:.2f}%')\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
